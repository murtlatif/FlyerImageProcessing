{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "product_classification_cosine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-YHzzXSHptF"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YnZVSOkHEe-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import stats\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrtQdqGHTCu"
      },
      "source": [
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQRLU6mkHdTo"
      },
      "source": [
        "# load data\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "sentences = df['text']\n",
        "true_labels = df['label']\n",
        "categories = [\n",
        "    \"produce\", # fruits, vegetables 0\n",
        "    \"deli\",     # chicken, beef, eggs 1\n",
        "    \"grocery\",  # chips, pop, jello, baking, crackers, flour 2\n",
        "    \"bakery\",   # cakes, breads, cookies 3\n",
        "    \"dairy\",    # butter, milk, yoghurt 4\n",
        "]\n",
        "\n",
        "sentence_embeddings = model.encode(sentences)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cAy9-AKITRp"
      },
      "source": [
        "def kNearestNeighbor(sim, k):\n",
        "    sim = sim.copy()\n",
        "    m,n = sim.shape\n",
        "    for i in range(m):\n",
        "        # only keep the k largest number\n",
        "        sim[i, sim[i].argsort()[:-k]] = 0\n",
        "    return sim"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJuFS5ubLhkJ"
      },
      "source": [
        "def eval_train(product_idx, method=\"mode\"):\n",
        "  \"\"\"\n",
        "  Use to evaluate on train dataset.\n",
        "\n",
        "  product_idx: (int) index within train dataset\n",
        "  method: (str) \"mode\" or \"top\". If mode, returns most common prediction.\n",
        "          If \"top\", returns top prediction\n",
        "  \"\"\"\n",
        "  # get sims\n",
        "  sims = cosine_similarity(\n",
        "      [sentence_embeddings[product_idx]],\n",
        "      sentence_embeddings[np.arange(len(sentence_embeddings))!=product_idx]\n",
        "  )\n",
        "  # find 6 nearest neighbours\n",
        "  nearest = kNearestNeighbor(sims, 6).tolist()[0]\n",
        "  # collect indices + values\n",
        "  idxs = [(i, element) for i, element in enumerate(nearest) if element]\n",
        "  # sort highest to lowest\n",
        "  idxs.sort(key=lambda x: x[1], reverse=True)\n",
        "  # get labels from each prediction\n",
        "  preds = [true_labels[i] for i, val in idxs]\n",
        "  if method == \"top\":\n",
        "    # return top prediction\n",
        "    return preds[0]\n",
        "  if method == \"mode\":\n",
        "    # return common prediction\n",
        "    # return mode(preds)\n",
        "    return stats.mode(preds)[0][0]\n"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBkQUkiKTJE4"
      },
      "source": [
        "def eval_test(product, method=\"mode\"):\n",
        "  \"\"\"\n",
        "  Use to evaluate on new products\n",
        "\n",
        "  product: (str) product name\n",
        "  method: (str) \"mode\" or \"top\". If mode, returns most common prediction.\n",
        "          If \"top\", returns top prediction\n",
        "  \"\"\"\n",
        "  # get sims\n",
        "  sims = cosine_similarity(\n",
        "      model.encode([product]),\n",
        "      sentence_embeddings\n",
        "  )\n",
        "  # find 6 nearest neighbours\n",
        "  nearest = kNearestNeighbor(sims, 6).tolist()[0]\n",
        "  # collect indices + values\n",
        "  idxs = [(i, element) for i, element in enumerate(nearest) if element]\n",
        "  # sort highest to lowest\n",
        "  idxs.sort(key=lambda x: x[1], reverse=True)\n",
        "  # get labels from each prediction\n",
        "  preds = [true_labels[i] for i, val in idxs]\n",
        "  if method == \"top\":\n",
        "    # return top prediction\n",
        "    return preds[0]\n",
        "  if method == \"mode\":\n",
        "    # return common prediction\n",
        "    # return mode(preds)\n",
        "    return stats.mode(preds)[0][0]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8RsDW5OnfY"
      },
      "source": [
        "# evaluate on training dataset\n",
        "mode_predictions = []\n",
        "top_predictions = []\n",
        "for i in range(len(sentence_embeddings)):\n",
        "  mode_predictions.append(eval_train(i))\n",
        "  top_predictions.append(eval_train(i, method=\"top\"))"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3XFSr_8P8S5",
        "outputId": "a5010fd0-6bbd-469d-ef65-a9bfc1ecb06c"
      },
      "source": [
        "# get accuracies\n",
        "print(accuracy_score(mode_predictions, true_labels))\n",
        "print(accuracy_score(top_predictions, true_labels))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6830985915492958\n",
            "0.6713615023474179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie4abb_rSEnO",
        "outputId": "00bac908-6d0b-402c-90b3-110a3d60a901"
      },
      "source": [
        "# confusion matrices\n",
        "print(confusion_matrix(mode_predictions, true_labels))\n",
        "print(confusion_matrix(top_predictions, true_labels))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[153  25  43   3  18]\n",
            " [  3  39   1   1   1]\n",
            " [  4   2  31   6   1]\n",
            " [  1   0   5  12   2]\n",
            " [  3   2  12   2  56]]\n",
            "[[125  13  26   1  12]\n",
            " [ 10  43   3   2   2]\n",
            " [ 11   5  48   6   2]\n",
            " [  4   1   2  11   3]\n",
            " [ 14   6  13   4  59]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73gpXmoINoq5",
        "outputId": "66435b92-95cc-4d9d-b222-2105aafac34f"
      },
      "source": [
        "# test new products here\n",
        "product = \"Western family mushrooms\"\n",
        "print(categories[eval_test(product, method=\"top\")])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "produce\n"
          ]
        }
      ]
    }
  ]
}